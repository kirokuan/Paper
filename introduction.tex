\chapter{Introduction}
\setlength{\baselineskip}{1.5em}
\setlength{\parindent}{2em}
\setlength{\parskip}{1em}

\section{Abstract}

How to make the sentence embedding with its own semantics more precisely is a study of interest, since it is beneficial for several NLP tasks like machine translation, sentiment analysis. 
The volume of internet text grows so enormously and rapidly, and the new derivative or new word keep growing as well.
It becomes more critical for many applications to make the information can be extracted more efficiently and precisely.  
Chinese forums, blogs or microblog expand especially rapidly. The studies tried to vectorize the sentences with deep learning approaches in more general way to make it invariant to the languages properties.  


Recently word2vec\cite{word2vec} is considered to work for evaluating word semantics in general cases.  
Additionally, the character of word2vec is invariant to the languages. Nevertheless, 
the embedding in sentence or phase level is more complicated, it is related to the sentence structure,  
intention or context. There are several methods raised in recent years, like Siamese-CBOW, fasttext. 
Most of them are able to train batch of text to construct semantic vectors.

Most dataset for NLP work are still in Indo-European Languages, including English, Spanish. Wiki suggested that 46\% people speak Indo-European as their first language. 
Although Indo-European languages are spread widely, there are also other languages like Chinese, Japanese, which own their special properties.

\section{Purpose}

So far, most studies about the sentiment analysis are conducted mainly in English, or in multilingual environments
, which are from the forums, reviews platforms contributed by the worldwide users. Most techniques also are aimed at being invariant to language properties or appliable to multilanguage environment. 
However, few of them evaluate the effectiveness of these techniques to other languages, neither they evaluate the multilingual dataset with considering the characteristic of other languages.   
We are also interested if those models also work in Chinese or other languages, and if the algorithm is invariant to the language grammar or language property. 
In this paper, we demonstrate the modern methods on practical data, and compare it with traditional methods.