\chapter{Methods}


We used jieba and dictionary to segment to post.



\section{The model introduction}

Here are some models we tested.

1. TF-IDF + SVM \\

	The conventional way to evaluate the semantics based on the occurrence of words and term, and it also takes the occurrence of word in global context into consideration.  It's simple and effective, but it still suffers from some disadvantages like data sparsity and high dimension. \\
	
2. FastText \cite{joulin2016fasttext}\\
	
	The structure of FastText is similar to CBOW of Mikolov et al. (2013), and it uses the softmax to compute the probabilities for predefined classes. The word representation is looked up through a table and finally averaged into the text representation. Finally it uses the linear classification.

3. Paragraph vector \cite{PVDB}\\

	This is method is purposed in \cite{PVDB}. The idea is obtain the summary of paragraphs,sentences or documents. There are 2 different algorithms we tested, which are dm (distributed memory) and dbow(distributed bag of words).

We use the implementation of Gensim and use SVM with linear kernel to classify.

4. Siamese-Cbow\cite{kenter2016siamesecbow}\\

	The method computes a sentence embedding is to average the embeddings of its
constituent words, instead of using pre-trained word embedding.

	We used the implementation (https://bitbucket.org/TomKenter/siamese-cbow/overview) from the author, and made it compatible with python3 for better compatibility with unicode.
